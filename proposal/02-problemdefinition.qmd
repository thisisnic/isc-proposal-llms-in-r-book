---
bibliography: references.bib
---

# The Problem

LLMs and AI are having a huge impact on software engineering and data science, and the tools available, model capabilities, and advice is rapidly changing.  Guidance on effective use of the available tools is scattered across difference locations, such as model vendor guidance, R package vignettes, and blog posts by community members.  

While existing resources provide valuable solution-oriented guidance on topics like how to use specific functions and packages, R users are left without a clear framework for understanding the problem space.  This involves decisions about whether and when to use LLMs; for example, in using them to explain results to stakeholders, embedding code in analysis pipelines while maintaining data privacy, and generating R code.  

As a result, users must piece together knowledge from multiple sources, with no obvious place to start.  There is real risk of misapplying methods, and wasting time and effort.  The problem exists for many R users including data scientists, analysts, and educators who want to integrate LLMs into analysis, teaching, and tooling. 

This problem could be solved by consolidating best practices, examples, and guidance into a single structured resource.  This would give R users confidence in having a reliable foundation for experimenting with LLMs and strengthen R's position as a community invested in open, inclusive and responsible use of technology.

Due to the speed at which things are moving in LLMs/AI, it's unlikely that this kind of resource would be a good candidate for a permanent, static reference like a book published via a traditional publisher.  Instead, the value lies in creating a living, community-oriented resource that can be updated as packages evolve, new methods emerge, and best practices shift. By structuring it as an open, ongoing work rather than a fixed text, the book can remain relevant to R users and avoid the obsolescence that traditional publications in this domain are likely to face.