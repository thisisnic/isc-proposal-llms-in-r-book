---
bibliography: references.bib
---

# The Problem

Large language models (LLMs) and AI are rapidly reshaping how data scientists and other users of analytical software work, but for R users, guidance on effective use of these tools is fragmented. Blog posts, package vignettes, and community discussions contain excellent advice, but it is scattered across platforms.  More generic guidance is often targeted more at software engineers than applied data analysts.

This fragmentation means that users must piece together knowledge from multiple sources with no obvious place to start and risk misapplying methods.  The problem exists for R users including data scientists, analysts, and educators who want to integrate LLMs into analysis, teaching, and tooling. 

Solving this problem by consolidating best practices and tools into a single structured resource will give R users a reliable foundation for experimenting with LLMs and strengthen R's position as a platform for responsible, reproducible AI.

Due to the speed at which things are moving in LLMs/AI, it's unlikely that this kind of book would be a good candidate for a permanent, static reference. Instead, the value lies in creating a living, community-oriented resource that can be updated as packages evolve, new methods emerge, and best practices shift. By structuring it as an open, ongoing work rather than a fixed text, the book can remain relevant to R users navigating a fast-changing landscape while avoiding the obsolescence that traditional publications in this domain are likely to face.